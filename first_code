#first thing we do is datacleaning and standardization (standardization is recommended for regularization)
df_no_labels= select(df_training[1:5000,:], Not(:labels))
df_clean_const_no_labels = df_no_labels[:, std.(eachcol(df_no_labels)) .!= 0]
colum_labels= df_training.labels
stand_gene_mach= fit!(machine(Standardizer(), df_clean_const_no_labels));
df_training_stand_no_labels= MLJ.transform(stand_gene_mach,df_clean_const_no_labels)
df_training_stand= hcat(df_training_stand_no_labels, colum_labels)
df_training_stand[:,end-3:end] #to chech if labels were correctly added back 
rename!(df_training_stand,:x1 => :labels)
coerce!(df_training_stand, :labels => Multiclass);

we try regularization for lambda= 1e-3 with the standardized and cleaned data (1:4000)-> training, (4001:5000)-> validation
gene_fit_reg = machine(MultinomialClassifier(penalty = :l1, lambda = 1e-3),
                        select(df_training_stand[1:4000,:], Not(:labels)),
                        df_training_stand.labels[1:4000])|> fit!
			
function losses(machine, input, response)
    (negative_loglikelihood = sum(log_loss(predict(machine, input), response)),
     misclassification_rate = mean(predict_mode(machine, input) .!= response),
     accuracy = accuracy(predict_mode(machine, input), response),
     auc = auc(predict(machine, input), response),
	 confusion_matrix = confusion_matrix(predict_mode(machine, input), response))
end;
losses(gene_fit_reg, select(df_training_stand[1:4000,:], Not(:labels)), df_training_stand.labels[1:4000])
#result train accuracy:
negative_loglikelihood
77.3269
misclassification_rate
0.0
accuracy
1.0
auc
1.0
confusion_matrix
              ┌─────────────────────────────────────────┐
              │              Ground Truth               │
┌─────────────┼─────────────┬─────────────┬─────────────┤
│  Predicted  │     CBP     │    KAT5     │    eGFP     │
├─────────────┼─────────────┼─────────────┼─────────────┤
│     CBP     │    1483     │      0      │      0      │
├─────────────┼─────────────┼─────────────┼─────────────┤
│    KAT5     │      0      │    1270     │      0      │
├─────────────┼─────────────┼─────────────┼─────────────┤
│    eGFP     │      0      │      0      │    1247     │
└─────────────┴─────────────┴─────────────┴─────────────┘
losses(gene_fit_reg, select(df_training_stand[4001:5000,:], Not(:labels)), df_training_stand.labels[4001:5000])
#result validation accuracy:
negative_loglikelihood
290.723
misclassification_rate
0.103
accuracy
0.897
auc
0.951294
confusion_matrix
              ┌─────────────────────────────────────────┐
              │              Ground Truth               │
┌─────────────┼─────────────┬─────────────┬─────────────┤
│  Predicted  │     CBP     │    KAT5     │    eGFP     │
├─────────────┼─────────────┼─────────────┼─────────────┤
│     CBP     │     330     │     48      │      4      │
├─────────────┼─────────────┼─────────────┼─────────────┤
│    KAT5     │     37      │     231     │      5      │
├─────────────┼─────────────┼─────────────┼─────────────┤
│    eGFP     │      2      │      7      │     336     │
└─────────────┴─────────────┴─────────────┴─────────────┘
